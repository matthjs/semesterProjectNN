{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN in Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import math\n",
    "import numpy as onp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import grad, vmap, jit\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "from shutil import copy\n",
    "from shutil import move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1)\n",
    "TRAINING_ON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre - and Postprocessing\n",
    "$$\n",
    "\\mathcal{D} : \\text{CSV} \\rightarrow [0,1]^{K \\times n_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D(df):\n",
    "    time = df[\"time\"].values\n",
    "    notes = df[\"notes\"].values\n",
    "    velocity = df[\"velocity\"].values\n",
    "    h = {}\n",
    "    h[35] = 0\n",
    "    h[36] = 1\n",
    "    h[38] = 2\n",
    "    h[41] = 3\n",
    "    h[42] = 4\n",
    "    h[43] = 5\n",
    "    h[44] = 6\n",
    "    h[45] = 7\n",
    "    h[59] = 8\n",
    "    h[60] = 9\n",
    "    h[61] = 10\n",
    "    h[63] = 11\n",
    "    h[68] = 12\n",
    "    h[76] = 13\n",
    "    h[82] = 14\n",
    "    h[87] = 15\n",
    "    h[88] = 16\n",
    "    h[89] = 17\n",
    "    h[91] = 18\n",
    "    h[93] = 19\n",
    "\n",
    "    dim = len(h)\n",
    "    u = list(itertools.repeat(np.zeros(dim), max(time)+1))\n",
    "\n",
    "    for i in range(len(notes)):\n",
    "        v = [0]*dim\n",
    "        v[h[int(notes[i])]] = int(velocity[i]) / 127\n",
    "        if (np.any(u[time[i]])):        #If the current vector is not the zero vector\n",
    "            u[time[i]] = u[time[i]] + np.array(v)\n",
    "        else:\n",
    "            u[time[i]] = np.array(v)\n",
    "    \n",
    "    y_train = u[1:]\n",
    "    y_train.append(np.zeros(dim))\n",
    "    return np.array(u), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  \\mathcal{D}^{-1} : [0,1]^{K \\times n_i} \\rightarrow \\text{CSV}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_inv(y):\n",
    "    h_inv = {}\n",
    "    h_inv[0] = 35\n",
    "    h_inv[1] = 36\n",
    "    h_inv[2] = 38\n",
    "    h_inv[3] = 41\n",
    "    h_inv[4] = 42\n",
    "    h_inv[5] = 43\n",
    "    h_inv[6] = 44\n",
    "    h_inv[7] = 45\n",
    "    h_inv[8] = 59\n",
    "    h_inv[9] = 60\n",
    "    h_inv[10] = 61\n",
    "    h_inv[11] = 63\n",
    "    h_inv[12] = 68\n",
    "    h_inv[13] = 76\n",
    "    h_inv[14] = 82\n",
    "    h_inv[15] = 87\n",
    "    h_inv[16] = 88\n",
    "    h_inv[17] = 89\n",
    "    h_inv[18] = 91\n",
    "    h_inv[19] = 93\n",
    "\n",
    "    dfo = pd.DataFrame([], columns= [\"track\", \"time\", \"control\"\n",
    "                            ,\"channel\", \"notes\", \"velocity\"])\n",
    "    time_new = []\n",
    "    notes_new = []\n",
    "    velocity_new = []\n",
    "\n",
    "    for n in range(len(y)):\n",
    "        if (np.any(y[n])):\n",
    "            yn = y[n]\n",
    "            for i in range(len(yn)):\n",
    "                v = (int)(yn[i] * 127)\n",
    "                if (v > 0):\n",
    "                    time_new.append(n)\n",
    "                    velocity_new.append(v)\n",
    "                    notes_new.append(h_inv[i])\n",
    "\n",
    "    track_new = [2]*len(time_new)       # arbitrary\n",
    "    note_is_played_new = [\"Note_on_c\"]*len(time_new)\n",
    "    channel_new = [9]*len(time_new)     # 9 for drum\n",
    "\n",
    "    dfo[\"track\"] = track_new\n",
    "    dfo[\"note_is_played\"] = note_is_played_new\n",
    "    dfo[\"channel\"] = channel_new\n",
    "    dfo[\"time\"] = time_new\n",
    "    dfo[\"velocity\"] = velocity_new\n",
    "    dfo[\"notes\"] = notes_new\n",
    "\n",
    "    latestTime = time_new[-1] + 10\n",
    "\n",
    "    pre = [[0,0, \"Header\", 1, 2, 480, ''],\n",
    "            [1, 0, \"Start_track\", '', '', '', ''],\n",
    "            [1, 0, \"Time_signature\", 4, 2, 24, 8],\n",
    "            [1, 0, \"Title_t\", \"\\\"from model\\\"\", '', '', ''],\n",
    "            [1, 0, \"End_track\", '', '', '', ''],\n",
    "            [2, 0, \"Start_track\", '', '', '', '']]\n",
    "\n",
    "    post = [[2, latestTime, \"End_track\", '', '', '', ''],\n",
    "            [0, 0, \"End_of_file\", '', '', '', '']]\n",
    "\n",
    "    dfo[\"filler\"] = ''\n",
    "    # adding pre and post\n",
    "    for i in range(len(pre)):\n",
    "        dfo.loc[i] = pre[i]\n",
    "    for j in range(len(post)):\n",
    "        dfo.loc[len(dfo)+j] = post[j]\n",
    "\n",
    "    #dfo.to_csv(\"new.csv\", index = False, header = False)\n",
    "    return dfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTracks(df):\n",
    "    subDataFrames = []\n",
    "    startingIdx = -1\n",
    "    # get each track as seperate dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        if (row[\"control\"] == \" Start_track\"):\n",
    "            startingIdx = idx\n",
    "        elif (row[\"control\"] == \" End_track\"):\n",
    "            subDataFrames.append(df[startingIdx : idx + 1])\n",
    "    return subDataFrames\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a dataFrame converted from a MIDI file\n",
    "returns a list of dataFrames of just the channel 9 tracks\n",
    "and removes all rows where the control columns is\n",
    "not \"note_on_c\"\n",
    "i.e. the drum tracks\n",
    "Meaning that if a song has multiple drum tracks the list\n",
    "will contain more than one dataframe.\n",
    "\"\"\"\n",
    "def getDrumTracks(df):\n",
    "    # get those tracks that are drum tracks\n",
    "    drumDataFrames = [d[d[\"control\"] == \" Note_on_c\"] for d in getTracks(df) if \" 9\" in list(d[\"channel\"])]\n",
    "    return drumDataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\mathcal{M} : \\text{MIDI} \\rightarrow \\text{CSV}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file already there\n",
      "csv file already there\n",
      "csv file already there\n",
      "csv file already there\n",
      "csv file already there\n",
      "csv file already there\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copies over the MIDI files to the folder \n",
    "where the can be converted.\n",
    "\n",
    "\"\"\"\n",
    "cwd = os.getcwd()\n",
    "\n",
    "os.chdir('../midi/NetworkInputMIDI')\n",
    "\n",
    "fileNames = []\n",
    "for m in os.listdir():\n",
    "    fileNames.append(m)\n",
    "    copy(m, '../midicsv-1.1')\n",
    "\n",
    "os.chdir('../midicsv-1.1')\n",
    "for m in fileNames:\n",
    "    command = \"midicsv\" + \" \" + m + \" \" + m[:-4] + \".csv\"\n",
    "    res = os.system(command)\n",
    "    os.remove(m)\n",
    "    try:\n",
    "        move(m[:-4] + \".csv\", '../NetworkInputCSV')\n",
    "    except:\n",
    "        print(\"csv file already there\")\n",
    "        os.remove(m[:-4] + \".csv\")\n",
    "\n",
    "# ensures that the cwd resets\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the csv files as panda dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\midi\\NetworkInputCSV\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../midi/NetworkInputCSV')\n",
    "print(os.getcwd())\n",
    "S = []  # S will be a list of tuples\n",
    "        # each tuple contains two input signals over time\n",
    "columnNames = [\"track\", \"time\", \"control\"\n",
    "                            , \"channel\", \"notes\", \"velocity\"]\n",
    "\n",
    "\"\"\"\n",
    "Loop through all the csv files in\n",
    "the network input folder\n",
    "\"\"\"\n",
    "drumTracks_df = []\n",
    "for csv in os.listdir():\n",
    "    # for now: generalize later\n",
    "    df = pd.read_csv(csv, skiprows=6, engine='python', names= columnNames)\n",
    "    drumTracks_df = drumTracks_df + getDrumTracks(df)\n",
    "    \"\"\"\n",
    "    if (csv == \"drumDemo.csv\"):\n",
    "        df = pd.read_csv(csv, skipfooter=2, skiprows=8, engine='python', names= columnNames)\n",
    "        u_train, y_train = D(df)\n",
    "        S.append((u_train, y_train))\n",
    "        df = pd.read_csv(csv, skipfooter=2, skiprows=8, engine='python', names= columnNames)\n",
    "        u_train, y_train = D(df)\n",
    "        S.append((u_train, y_train))\n",
    "        df = pd.read_csv(csv, skipfooter=2, skiprows=8, engine='python', names= columnNames)\n",
    "        u_train, y_train = D(df)\n",
    "        S.append((u_train, y_train))\n",
    "        df = pd.read_csv(csv, skipfooter=2, skiprows=8, engine='python', names= columnNames)\n",
    "        u_train, y_train = D(df)\n",
    "        S.append((u_train, y_train))\n",
    "    if (csv == \"Africa.csv\"):\n",
    "        africa_df = pd.read_csv(csv, skiprows=6, engine='python', names= columnNames)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#print(type(S))\n",
    "#u_ex, y_ex = S[0]\n",
    "#print(jax.tree_map(lambda x: x.shape, u_ex))\n",
    "#print(jax.tree_map(lambda x: x.shape, y_ex))\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hashmap that maps notes to right vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\networks\\RNNtest.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000040?line=7'>8</a>\u001b[0m             num \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(row[\u001b[39m\"\u001b[39m\u001b[39mnotes\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000040?line=8'>9</a>\u001b[0m             \u001b[39mset\u001b[39m\u001b[39m.\u001b[39madd(num)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000040?line=10'>11</a>\u001b[0m notes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mset\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000040?line=11'>12</a>\u001b[0m notes\u001b[39m.\u001b[39msort()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000040?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(notes)):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "print(type(drumTracks_df[3]))\n",
    "h = {}\n",
    "set = {-1}\n",
    "num = -1\n",
    "for d in drumTracks_df:\n",
    "    for idx, row in d.iterrows():\n",
    "        if int(row[\"notes\"]) != num:\n",
    "            num = int(row[\"notes\"])\n",
    "            set.add(num)\n",
    "\n",
    "notes = list(set)\n",
    "notes.sort()\n",
    "\n",
    "for idx in range(1, len(notes)):\n",
    "    h[notes(idx)] = idx\n",
    "\n",
    "print(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "drumTracks_df\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "S = []\n",
    "for d in drum_df:\n",
    "    u_train, y_train = D(d)\n",
    "    S.append((u_train, y_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153485, 20)\n",
      "(153485, 20)\n"
     ]
    }
   ],
   "source": [
    "u_ex, y_ex = S[0]\n",
    "print(jax.tree_map(lambda x: x.shape, u_ex))\n",
    "print(jax.tree_map(lambda x: x.shape, y_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RNN (with no LSTM units) is a neural network with recurrent connections (dynamical system)\n",
    "$$\n",
    "\\begin{array}{l l}\n",
    "          \\mathbf{x}(n+1) = \\sigma(W \\mathbf{x}(n) + W^{in}\\mathbf{u}(n+1) + \\mathbf{b}) \\\\\n",
    "          \\mathbf{y}(n) = f(W^{out} \\mathbf{x}(n)),\n",
    "\\end{array}\n",
    "$$\n",
    "Describes how the network activation state is updated and how output signal is generated. \n",
    "\n",
    "Input vector $\\mathbf{u}(n) \\in [0,1]^K$\n",
    "\n",
    "Activation/state vector $\\mathbf{x}(n) \\in \\mathbb{R}^L$\n",
    "\n",
    "Output vector $\\mathbf{y}(n) \\in \\mathbb{R}^K$\n",
    "\n",
    "Bias vector $\\mathbf{b} \\in \\mathbb{R}^L$\n",
    "\n",
    "$W^{in} \\in \\mathbb{R}^{L \\times K}, W \\in \\mathbb{R}^{L \\times L}, W^{out} \\in \\mathbb{R}^{K \\times L}$ are weight matrices charecterizing the connections between neurons in the layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "At time $n = 0$ the recurrent network state $\\mathbf{x}(0)$ is often set to the zero vector $\\mathbf{x}(0) = \\mathbf{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight_matrix(in_dim, out_dim, key, scale=1e-2):\n",
    "    w = jax.random.normal(key, (out_dim, in_dim))\n",
    "    return scale*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(dim, key, scale=1e-2):\n",
    "    b = jax.random.normal(key, (dim, ))\n",
    "    return scale*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state, params = (W^{in}, W, W^{out}, b)\n",
    "# sizes = (input dim, state dim, output dim.)\n",
    "def init_network(sizes, key):\n",
    "    keys = jax.random.split(key, len(sizes))\n",
    "    \n",
    "    Win = init_weight_matrix(sizes[0], sizes[1], keys[0])\n",
    "    W = init_weight_matrix(sizes[1], sizes[1], keys[1])\n",
    "    Wout = init_weight_matrix(sizes[1], sizes[2], keys[3])\n",
    "    b = init_bias(sizes[1], keys[2])\n",
    "\n",
    "    return (Win, W, Wout, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((125, 7), (125, 125), (7, 125), (125,))\n"
     ]
    }
   ],
   "source": [
    "K = 7 # K := input and output vector dim\n",
    "L = 125 # Reservoir or State Vector dim\n",
    "sizes = [K, L, K]\n",
    "params = init_network(sizes, key)\n",
    "print(jax.tree_map(lambda x: x.shape, params)) # printing shape of network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_og is initially the zero vector\n",
    "def forward_bp(params, u, x_og=np.zeros((L, ))):\n",
    "    \"\"\" Loop over the time steps of the input sequence\n",
    "    u[n] := [u_0, ..., u_{n_max}] where u_i \\in [0, 1]^K or (K, )\n",
    "    x_og: \\in R^L or (L, )\n",
    "    \"\"\"\n",
    "    Win, W, Wout, b = params\n",
    "    x = x_og.copy()\n",
    "\n",
    "    def apply_fun_scan(params, x, ut):\n",
    "        \"\"\" Perform single step update of the network.\n",
    "        x:  (L, )\n",
    "        un: (K, )\n",
    "        \"\"\"\n",
    "        Win, W, Wout, b = params\n",
    "        x = jax.nn.relu(\n",
    "            np.dot(Win, ut) + np.dot(W, x) + b\n",
    "        )\n",
    "        y = jax.nn.sigmoid(np.dot(Wout, x))\n",
    "        return x, y\n",
    "\n",
    "    f = functools.partial(apply_fun_scan, params)\n",
    "    _, Y = jax.lax.scan(f, x, u)\n",
    "    return Y\n",
    "\n",
    "batch_forward_bp = jax.vmap(forward_bp, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "Logistic regression is used for the case where you do not model loudness. Because there it is a categorical task (to hit or not to hit). But if you do model loudness you use the procedure linear regression. Meaning using the loss functions that are mentioned in the RNN section of the reader like MSE or quadratic loss.\n",
    "\n",
    "Time series prediction task $S = (\\mathbf{u}^{(i)}(n), \\mathbf{y}^{(i)}(n))_{i=1, ..., N;n=1, ..., n_i}$ where $\\mathbf{y}^{i}(n) = \\mathbf{u}^{(i)}(n+1)$\n",
    "For now: quadratic loss which is used in stationary tasks\n",
    "$$\n",
    "    L(\\hat{\\mathbf{Y}}_{i, \\theta}^{\\text{train}}, \\mathbf{Y}_i^{\\text{train}}) = \\parallel \\hat{\\mathbf{Y}}_{i, \\theta}^{\\text{train}} - \\mathbf{Y}_i^{\\text{train}} \\parallel^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization\n",
    "$$\n",
    "\\text{reg}(\\theta) = \\sum_{w \\in \\theta} w^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# could be made nicer\n",
    "def getParameterVector(params):\n",
    "    theta = []\n",
    "    for w in params:\n",
    "        for e in w:\n",
    "            if (e.size > 1):\n",
    "                for i in e:\n",
    "                    theta.append(i)\n",
    "            else:\n",
    "                theta.append(e)\n",
    "    return np.array(theta)\n",
    "\n",
    "def reg(params):\n",
    "    theta = getParameterVector(params)\n",
    "    return np.sum(np.square(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{R}^{\\text{emp}}(\\theta) = \\frac{1}{N} \\sum^{N}_{i=1} L(\\hat{\\mathbf{Y}}_{i, \\theta}^{\\text{train}}, \\mathbf{Y}_i^{\\text{train}}) + r^2 \\; \\text{reg}(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, u, y_true, alpha):\n",
    "    y_hat = batch_forward_bp(params, u)\n",
    "    return np.square(np.linalg.norm(np.subtract(y_hat, y_true))) + (alpha*alpha)*reg(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\theta^{(n+1)} = \\theta^{(n)} - \\mu \\nabla \\mathcal{R}^{\\text{emp}}(\\theta^{(n)}),\n",
    "$$\n",
    "\n",
    "$$\n",
    "   \\nabla \\mathcal{R}^{\\text{emp}}(\\theta^{(n)}) = \n",
    "\\bigg(\\frac{\\partial  R^{emp}}{\\partial  w_1}(\\theta^{(n)}), ...,\\frac{\\partial  R^{emp}}{\\partial w_D}(\\theta^{(n)}) \\bigg)',\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params, u, y_true, alpha, step_size=1e-2):\n",
    "    grads = jax.grad(loss)(params, u, y_true, alpha)\n",
    "    return [\n",
    "        w - step_size * dw\n",
    "        for w, dw in zip(params, grads)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\mathcal{A}(S) = \\theta_{\\text{opt}} = \\underset{\\theta \\in \\Theta}{\\text{argmin}} \\; \\underbrace{\\frac{1}{N} \\sum^N_{i=1} L(\\hat{\\mathbf{Y}}_{\\theta}^{\\text{train}}, \\mathbf{Y}^{\\text{train}})}_{\\mathcal{R}^{\\text{emp}}(\\theta)},\n",
    "$$\n",
    "$$\n",
    "    \\theta^{(n+1)} = \\theta^{(n)} - \\mu \\nabla \\mathcal{R}^{\\text{emp}}(\\theta^{(n)}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "s is a list of tuples \n",
    "[(u1, y1), (u2, y2), ...] -> ((u_1, u_2, ...), (y_1, y_2, ...))\n",
    "\"\"\"\n",
    "def unpack(s):\n",
    "    f1 = map(lambda x: x[0], s)\n",
    "    f2 = map(lambda x: x[1], s)\n",
    "    u_batch = np.array(list(f1))\n",
    "    y_batch = np.array(list(f2))\n",
    "    return (u_batch, y_batch)\n",
    "\n",
    "\"\"\"\n",
    "trains the network on the training data for n epochs\n",
    "in the cross validations setup the testing data is\n",
    "the validation set and is simply used to measure the\n",
    "testing loss next to the training loss\n",
    "\"\"\"\n",
    "def train(params, u_train, y_train, u_test, y_test, alpha, n_epochs=2):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        params = update(params, u_train, y_train, alpha)\n",
    "        train_loss.append(loss(params, u_train, y_train, alpha))\n",
    "        test_loss.append(loss(params, u_test, y_test, alpha))\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f'Epoch {epoch+1:>2} ({epoch_time:<.2f}s): ', end='')\n",
    "        print(f'train loss {train_loss[-1]:<5.2f} test loss {test_loss[-1]:<5.2f}', end='| ')\n",
    "    \n",
    "    return params\n",
    "\n",
    "def train2(params, u_train, y_train, r, n_epochs=1):\n",
    "    train_loss = []\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        params = update(params, u_train, y_train, r)\n",
    "        train_loss.append(loss(params, u_train, y_train, r))\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f'Epoch {epoch+1:>2} ({epoch_time:<.2f}s): ', end='')\n",
    "    return params\n",
    "\n",
    "if (TRAINING_ON):\n",
    "    # given S, params, loss/emprical risk, r (regularization)\n",
    "    # Hyperparameters\n",
    "    step_size=1e-2\n",
    "    k = 4   # k fold cross validation\n",
    "    # r is the hyperparameter (here r = alpha for the regularization)\n",
    "    validation_risk_r = []\n",
    "\n",
    "    # split S into k disjoint subsets\n",
    "\n",
    "    \"\"\"\n",
    "    Edge case: if k > amount of tuples (u_train, y_train) in S then n = 0\n",
    "    which will result in a valueError when constructing S_k.\n",
    "    Furthermore: the procedure will break down for single (u_train, y_train)\n",
    "    because then the reduced training set will be the empty set\n",
    "    \"\"\"\n",
    "    n = (int) (len(S)/k)\n",
    "\n",
    "    S_k = [S[i : i + n] for i in range(0, len(S), n)]\n",
    "\n",
    "    for r in range(0, 2):\n",
    "        validation_risk = []\n",
    "        for j in range(0, k):\n",
    "            V = S_k.pop(j)  # validation\n",
    "            T = [x for l in S_k for x in l]         # reduced training set\n",
    "            S_k.insert(j, V)\n",
    "            u_train, y_train = unpack(T)\n",
    "            u_val, y_val = unpack(V)\n",
    "            print(u_train.shape)\n",
    "            print(u_val.shape)\n",
    "            params = train(params, u_train, y_train, u_val, y_val, r)\n",
    "            validation_risk.append(loss(params, u_val, y_val, r))\n",
    "        validation_risk_r.append(np.mean(np.array(validation_risk)))\n",
    "\n",
    "    r_opt = np.argmin(np.array(validation_risk_r))\n",
    "    u_train, y_train = unpack(V)\n",
    "    params = train2(params, u_train, y_train, r_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Generation\n",
    "Get the file to prime the network with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fun_scan(params, x, un):\n",
    "    \"\"\" Perform single step update of the network.\n",
    "    x:  (L, ) at time step n -> x: (L, ) at time step n+1\n",
    "    un: (K, )\n",
    "    \"\"\"\n",
    "    Win, W, Wout, b = params\n",
    "    x = jax.nn.relu(\n",
    "        np.dot(Win, un) + np.dot(W, x) + b\n",
    "    )\n",
    "    y = jax.nn.sigmoid(np.dot(Wout, x))\n",
    "    return x, y\n",
    "\n",
    "df1 = pd.read_csv('drumDemo.csv', skipfooter=2, skiprows=8, engine='python', names= columnNames)\n",
    "u_prime = D(df1)[0]\n",
    "n_stop = 1000\n",
    "n_output = 8000\n",
    "\n",
    "y_signal = []\n",
    "x = np.zeros((L,))\n",
    "for n in range(n_stop):\n",
    "    x, y = apply_fun_scan(params, x, u_prime[n])\n",
    "    y_signal.append(y)\n",
    "\n",
    "for n in range(n_output):\n",
    "    x, y = apply_fun_scan(params, x, y)\n",
    "    y_signal.append(y)\n",
    "\n",
    "\"\"\"\n",
    "The non-trained network produces pretty much a signal that is zero everywhere\n",
    "the no csv file can be generated\n",
    "\"\"\"\n",
    "dfo = D_inv(np.array(y_signal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{M}^{-1} : \\text{CSV} \\rightarrow \\text{MIDI}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Puts generated CSV file in correct folder\n",
    "And generates the MIDI file and puts that in the correct\n",
    "folder as well.\n",
    "\"\"\"\n",
    "# for debugging: checking highest amplitude in output signal\n",
    "\"\"\"\n",
    "v = -99999999999999\n",
    "for e in y_signal:\n",
    "    if e.max() >= v:\n",
    "        v = e.max()\n",
    "print(v)\n",
    "\"\"\"\n",
    "\n",
    "os.chdir('../midi/NetworkOutputCSV')\n",
    "name = \"rnn.csv\"\n",
    "dfo.to_csv(name, index = False, header = False)\n",
    "copy(name, '../midicsv-1.1')\n",
    "os.chdir('../midicsv-1.1')\n",
    "\n",
    "command = \"csvmidi\" + \" \" + name + \" \" + name[:-4] + \".mid\"\n",
    "res = os.system(command)\n",
    "print(res)\n",
    "os.remove(name)\n",
    "try:\n",
    "    move(name[:-4] + \".mid\", '../NetworkOutputMIDI')\n",
    "except:\n",
    "    print(\"midi file already here\")\n",
    "    os.remove(name[:-4] + \".mid\")\n",
    "\n",
    "os.chdir(cwd)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e375b77a672b76be28c1e80386a6d4db61c866c142c6acff7bc94a65b4573147"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
