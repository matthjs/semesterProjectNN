{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN in Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import math\n",
    "import numpy as onp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import grad, vmap, jit\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import functools\n",
    "import os\n",
    "from shutil import copy\n",
    "from shutil import move\n",
    "import pickle\n",
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1)\n",
    "TRAINING_ON = True\n",
    "PROCESSING_AND_DATA_LOADING_ON = True\n",
    "SAVE_PARAMETERS = True\n",
    "READ_PARAMETERS = False\n",
    "RC_ON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre - and Postprocessing\n",
    "$$\n",
    "\\mathcal{D} : \\text{CSV} \\rightarrow [0,1]^{K \\times n_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a dataframe of a drum track and a hashmap\n",
    "for mapping the drum kits to an index of the vector.\n",
    "Returns the vectorized training set\n",
    "consisting of the training input and output.\n",
    "maxTime is for zero padding. If a signal is shorter than maxTime\n",
    "then it is zero padded\n",
    "\"\"\"\n",
    "def D(df, h, maxTime):\n",
    "\n",
    "    time = df[\"time\"].values\n",
    "    notes = df[\"notes\"].values\n",
    "    velocity = df[\"velocity\"].values\n",
    "\n",
    "    dim = len(h)\n",
    "    u = list(itertools.repeat(np.zeros(dim), max(time)+1))\n",
    "\n",
    "    for i in range(len(notes)):\n",
    "        v = [0]*dim\n",
    "        v[h[int(notes[i])]] = int(velocity[i]) / 127\n",
    "        if (np.any(u[time[i]])):        #If the current vector is not the zero vector\n",
    "            u[time[i]] = u[time[i]] + np.array(v)\n",
    "        else:\n",
    "            u[time[i]] = np.array(v)\n",
    "    \n",
    "    y_train = u[1:]\n",
    "    y_train.append(np.zeros(dim))\n",
    "\n",
    "    padding = maxTime - max(time)\n",
    "    return np.pad(np.array(u), ((0, padding), (0, 0)), \"constant\"), np.pad(np.array(y_train), ((0, padding), (0, 0)), \"constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  \\mathcal{D}^{-1} : [0,1]^{K \\times n_i} \\rightarrow \\text{CSV}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given an output vector and a hashmap\n",
    "for mapping indices of the vector to the\n",
    "appropriate note/drum kit. Returns a dataframe\n",
    "that can be converted to a csv file and then to a midi file\n",
    "\"\"\"\n",
    "def D_inv(y, h_inv):\n",
    "    dfo = pd.DataFrame([], columns= [\"track\", \"time\", \"control\"\n",
    "                            ,\"channel\", \"notes\", \"velocity\"])\n",
    "    time_new = []\n",
    "    notes_new = []\n",
    "    velocity_new = []\n",
    "\n",
    "    for n in range(len(y)):\n",
    "        if (np.any(y[n])):\n",
    "            yn = y[n]\n",
    "            for i in range(len(yn)):\n",
    "                v = (int)(yn[i] * 127)\n",
    "                if (v > 0):\n",
    "                    time_new.append(n)\n",
    "                    velocity_new.append(v)\n",
    "                    notes_new.append(h_inv[i])\n",
    "\n",
    "    track_new = [2]*len(time_new)       # arbitrary\n",
    "    note_is_played_new = [\"Note_on_c\"]*len(time_new)\n",
    "    channel_new = [9]*len(time_new)     # 9 for drum\n",
    "\n",
    "    dfo[\"track\"] = track_new\n",
    "    dfo[\"note_is_played\"] = note_is_played_new\n",
    "    dfo[\"channel\"] = channel_new\n",
    "    dfo[\"time\"] = time_new\n",
    "    dfo[\"velocity\"] = velocity_new\n",
    "    dfo[\"notes\"] = notes_new\n",
    "\n",
    "    latestTime = time_new[-1] + 10\n",
    "\n",
    "    pre = [[0,0, \"Header\", 1, 2, 480, ''],\n",
    "            [1, 0, \"Start_track\", '', '', '', ''],\n",
    "            [1, 0, \"Time_signature\", 4, 2, 24, 8],\n",
    "            [1, 0, \"Title_t\", \"\\\"from model\\\"\", '', '', ''],\n",
    "            [1, 0, \"End_track\", '', '', '', ''],\n",
    "            [2, 0, \"Start_track\", '', '', '', '']]\n",
    "\n",
    "    post = [[2, latestTime, \"End_track\", '', '', '', ''],\n",
    "            [0, 0, \"End_of_file\", '', '', '', '']]\n",
    "\n",
    "    dfo[\"filler\"] = ''\n",
    "    # adding pre and post\n",
    "    for i in range(len(pre)):\n",
    "        dfo.loc[i] = pre[i]\n",
    "    for j in range(len(post)):\n",
    "        dfo.loc[len(dfo)+j] = post[j]\n",
    "\n",
    "    #dfo.to_csv(\"new.csv\", index = False, header = False)\n",
    "    return dfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a list of dataframes for each track\n",
    "seperated by \"start track\" and \"end track\"\n",
    "\"\"\"\n",
    "def getTracks(df):\n",
    "    subDataFrames = []\n",
    "    startingIdx = -1\n",
    "    # get each track as seperate dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        if (row[\"control\"] == \" Start_track\"):\n",
    "            startingIdx = idx\n",
    "        elif (row[\"control\"] == \" End_track\"):\n",
    "            subDataFrames.append(df[startingIdx : idx + 1])\n",
    "    return subDataFrames\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Given a dataFrame converted from a MIDI file\n",
    "returns a list of dataFrames of just the channel 9 tracks\n",
    "and removes all rows where the control column is\n",
    "not \"note_on_c\"\n",
    "i.e. the drum tracks\n",
    "Meaning that if a song has multiple drum tracks the list\n",
    "will contain more than one dataframe.\n",
    "\"\"\"\n",
    "def getDrumTracks(df):\n",
    "    # get those tracks that are drum tracks\n",
    "    drumDataFrames = [d[d[\"control\"] == \" Note_on_c\"] for d in getTracks(df) if \" 9\" in list(d[\"channel\"])]\n",
    "    return drumDataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\mathcal{M} : \\text{MIDI} \\rightarrow \\text{CSV}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file already there\n",
      "csv file already there\n",
      "csv file already there\n",
      "csv file already there\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Copies over the MIDI files to the folder \n",
    "where the can be converted.\n",
    "\n",
    "\"\"\"\n",
    "cwd = os.getcwd()\n",
    "\n",
    "os.chdir('../midi/NetworkInputMIDI')\n",
    "\n",
    "fileNames = []\n",
    "for m in os.listdir():\n",
    "    fileNames.append(m)\n",
    "    copy(m, '../midicsv-1.1')\n",
    "\n",
    "os.chdir('../midicsv-1.1')\n",
    "for m in fileNames:\n",
    "    command = \"midicsv\" + \" \" + m + \" \" + m[:-4] + \".csv\"\n",
    "    res = os.system(command)\n",
    "    os.remove(m)\n",
    "    try:\n",
    "        move(m[:-4] + \".csv\", '../NetworkInputCSV')\n",
    "    except:\n",
    "        print(\"csv file already there\")\n",
    "        os.remove(m[:-4] + \".csv\")\n",
    "\n",
    "# ensures that the cwd resets\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the csv files as panda dataframes (get just the drum tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../midi/NetworkInputCSV')\n",
    "\n",
    "columnNames = [\"track\", \"time\", \"control\"\n",
    "                                , \"channel\", \"notes\", \"velocity\"]\n",
    "\n",
    "\"\"\"\n",
    "Loop through all the csv files in\n",
    "the network input folder\n",
    "\"\"\"\n",
    "drumTracks_df = []\n",
    "for csv in os.listdir():\n",
    "    # for now: generalize later\n",
    "    df = pd.read_csv(csv, skiprows=6, engine='python', names= columnNames)\n",
    "    df.dropna()\n",
    "    drumTracks_df = drumTracks_df + getDrumTracks(df)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hashmap that maps notes to right vector index and additionally\n",
    "1. normalize time\n",
    "2. get max time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       track    time     control channel  notes  velocity\n",
      "5865      11       0   Note_on_c       9     44      58.0\n",
      "5866      11       0   Note_on_c       9     35      89.0\n",
      "5867      11       0   Note_on_c       9     63      74.0\n",
      "5871      11      96   Note_on_c       9     44      36.0\n",
      "5873      11     192   Note_on_c       9     44      36.0\n",
      "...      ...     ...         ...     ...    ...       ...\n",
      "14869     11  151768   Note_on_c       9     44      34.0\n",
      "14871     11  151864   Note_on_c       9     44      51.0\n",
      "14872     11  151864   Note_on_c       9     68      52.0\n",
      "14876     11  151960   Note_on_c       9     44      48.0\n",
      "14877     11  151960   Note_on_c       9     68      35.0\n",
      "\n",
      "[4405 rows x 6 columns],        track    time     control channel  notes  velocity\n",
      "14888     12       0   Note_on_c       9     35     115.0\n",
      "14890     12     288   Note_on_c       9     35     122.0\n",
      "14892     12     384   Note_on_c       9     35     122.0\n",
      "14894     12     768   Note_on_c       9     35     122.0\n",
      "14896     12    1056   Note_on_c       9     35     121.0\n",
      "...      ...     ...         ...     ...    ...       ...\n",
      "16072     12  150816   Note_on_c       9     35     122.0\n",
      "16074     12  150912   Note_on_c       9     35     122.0\n",
      "16076     12  151296   Note_on_c       9     35     122.0\n",
      "16078     12  151584   Note_on_c       9     35     121.0\n",
      "16080     12  151680   Note_on_c       9     35     122.0\n",
      "\n",
      "[597 rows x 6 columns],        track    time     control channel  notes  velocity\n",
      "16089     13       0   Note_on_c       9     41     107.0\n",
      "16091     13     772   Note_on_c       9     41     107.0\n",
      "16093     13    1536   Note_on_c       9     41     107.0\n",
      "16095     13    2304   Note_on_c       9     41     107.0\n",
      "16097     13    3072   Note_on_c       9     41     107.0\n",
      "...      ...     ...         ...     ...    ...       ...\n",
      "16499     13  148224   Note_on_c       9     41     107.0\n",
      "16501     13  148992   Note_on_c       9     41     107.0\n",
      "16503     13  149760   Note_on_c       9     41     107.0\n",
      "16505     13  150528   Note_on_c       9     41     107.0\n",
      "16507     13  151296   Note_on_c       9     41     107.0\n",
      "\n",
      "[211 rows x 6 columns],        track    time     control channel  notes  velocity\n",
      "16516     14       0   Note_on_c       9     44      75.0\n",
      "16518     14      96   Note_on_c       9     44      47.0\n",
      "16520     14     192   Note_on_c       9     44      47.0\n",
      "16522     14     288   Note_on_c       9     44      62.0\n",
      "16524     14     384   Note_on_c       9     44      80.0\n",
      "...      ...     ...         ...     ...    ...       ...\n",
      "19672     14  151584   Note_on_c       9     44      62.0\n",
      "19674     14  151680   Note_on_c       9     44      96.0\n",
      "19676     14  151776   Note_on_c       9     44      44.0\n",
      "19678     14  151872   Note_on_c       9     44      66.0\n",
      "19680     14  151968   Note_on_c       9     44      62.0\n",
      "\n",
      "[1583 rows x 6 columns],        track    time     control channel  notes  velocity\n",
      "19689     15       0   Note_on_c       9     59      44.0\n",
      "19691     15     384   Note_on_c       9     59      44.0\n",
      "19693     15     772   Note_on_c       9     59      44.0\n",
      "19695     15    1152   Note_on_c       9     59      44.0\n",
      "19697     15    1536   Note_on_c       9     59      44.0\n",
      "...      ...     ...         ...     ...    ...       ...\n",
      "20469     15  149760   Note_on_c       9     59      44.0\n",
      "20471     15  150144   Note_on_c       9     59      44.0\n",
      "20473     15  150528   Note_on_c       9     59      44.0\n",
      "20475     15  150912   Note_on_c       9     59      44.0\n",
      "20477     15  151296   Note_on_c       9     59      44.0\n",
      "\n",
      "[395 rows x 6 columns],        track   time     control channel  notes  velocity\n",
      "20486     16      0   Note_on_c       9     60     107.0\n",
      "20488     16   6140   Note_on_c       9     60     107.0\n",
      "20490     16   9216   Note_on_c       9     60     107.0\n",
      "20492     16  11516   Note_on_c       9     60     107.0\n",
      "20494     16  12288   Note_on_c       9     60     107.0\n",
      "20496     16  13056   Note_on_c       9     60     107.0\n",
      "20498     16  13532   Note_on_c       9     60      98.0\n",
      "20500     16  13820   Note_on_c       9     60     107.0\n",
      "20502     16  39928   Note_on_c       9     60     107.0\n",
      "20504     16  46084   Note_on_c       9     60     107.0\n",
      "20506     16  49144   Note_on_c       9     60     107.0\n",
      "20508     16  51452   Note_on_c       9     60     107.0\n",
      "20510     16  52228   Note_on_c       9     60     107.0\n",
      "20512     16  52996   Note_on_c       9     60     107.0\n",
      "20514     16  53468   Note_on_c       9     60      98.0\n",
      "20516     16  53764   Note_on_c       9     60     107.0\n",
      "20518     16  72960   Note_on_c       9     60     107.0\n",
      "20520     16  79108   Note_on_c       9     60     107.0\n",
      "20522     16  82176   Note_on_c       9     60     107.0\n",
      "20524     16  84480   Note_on_c       9     60     107.0\n",
      "20526     16  85244   Note_on_c       9     60     107.0\n",
      "20528     16  86012   Note_on_c       9     60     107.0\n",
      "20530     16  86492   Note_on_c       9     60      98.0,        track    time     control channel  notes  velocity\n",
      "20539     17       0   Note_on_c       9     61      96.0\n",
      "20541     17     768   Note_on_c       9     61     104.0\n",
      "20543     17    1536   Note_on_c       9     61      96.0\n",
      "20545     17    2304   Note_on_c       9     61     104.0\n",
      "20547     17    3072   Note_on_c       9     61      96.0\n",
      "...      ...     ...         ...     ...    ...       ...\n",
      "20925     17  148228   Note_on_c       9     61     104.0\n",
      "20927     17  148992   Note_on_c       9     61      96.0\n",
      "20929     17  149764   Note_on_c       9     61     104.0\n",
      "20931     17  150528   Note_on_c       9     61      96.0\n",
      "20933     17  151300   Note_on_c       9     61     104.0\n",
      "\n",
      "[198 rows x 6 columns],        track    time     control channel  notes  velocity\n",
      "20942     18       0   Note_on_c       9     63      96.0\n",
      "20944     18     384   Note_on_c       9     63     104.0\n",
      "20946     18     768   Note_on_c       9     63      96.0\n",
      "20948     18     864   Note_on_c       9     63      72.0\n",
      "20950     18    1156   Note_on_c       9     63     100.0\n",
      "...      ...     ...         ...     ...    ...       ...\n",
      "21916     18  150528   Note_on_c       9     63      96.0\n",
      "21918     18  150912   Note_on_c       9     63     104.0\n",
      "21920     18  151296   Note_on_c       9     63      96.0\n",
      "21922     18  151392   Note_on_c       9     63      72.0\n",
      "21924     18  151680   Note_on_c       9     63     100.0\n",
      "\n",
      "[492 rows x 6 columns],        track    time     control channel  notes  velocity\n",
      "21933     19       0   Note_on_c       9     68      62.0\n",
      "21935     19     288   Note_on_c       9     68      31.0\n",
      "21937     19     480   Note_on_c       9     68      67.0\n",
      "21939     19     864   Note_on_c       9     68      50.0\n",
      "21941     19    1156   Note_on_c       9     68      67.0\n",
      "...      ...     ...         ...     ...    ...       ...\n",
      "23087     19  147744   Note_on_c       9     68      31.0\n",
      "23089     19  147936   Note_on_c       9     68      67.0\n",
      "23091     19  148320   Note_on_c       9     68      50.0\n",
      "23093     19  148608   Note_on_c       9     68      67.0\n",
      "23095     19  148704   Note_on_c       9     68      46.0\n",
      "\n",
      "[582 rows x 6 columns],        track   time     control channel  notes  velocity\n",
      "23104     20      0   Note_on_c       9     76      74.0\n",
      "23106     20     92   Note_on_c       9     76      35.0\n",
      "23108     20    188   Note_on_c       9     76      40.0\n",
      "23110     20    284   Note_on_c       9     76      44.0\n",
      "23112     20    384   Note_on_c       9     76      64.0\n",
      "...      ...    ...         ...     ...    ...       ...\n",
      "23682     20  85916   Note_on_c       9     76      36.0\n",
      "23684     20  86020   Note_on_c       9     76      40.0\n",
      "23686     20  86204   Note_on_c       9     76      80.0\n",
      "23688     20  86396   Note_on_c       9     76      44.0\n",
      "23690     20  86588   Note_on_c       9     76      44.0\n",
      "\n",
      "[294 rows x 6 columns],        track  time     control channel  notes  velocity\n",
      "23699     21     0   Note_on_c       9     87      82.0\n",
      "23701     21    16   Note_on_c       9     87     107.0,        track   time     control channel  notes  velocity\n",
      "23710     22      0   Note_on_c       9     88      82.0\n",
      "23712     22     16   Note_on_c       9     88     107.0\n",
      "23714     22  72960   Note_on_c       9     88      82.0\n",
      "23716     22  72976   Note_on_c       9     88     107.0,        track   time     control channel  notes  velocity\n",
      "23725     23      0   Note_on_c       9     89      83.0\n",
      "23727     23     20   Note_on_c       9     89     107.0\n",
      "23729     23    376   Note_on_c       9     89      78.0\n",
      "23731     23    400   Note_on_c       9     89     107.0\n",
      "23733     23    860   Note_on_c       9     89      91.0\n",
      "23735     23    888   Note_on_c       9     89     107.0\n",
      "23737     23  39936   Note_on_c       9     89      83.0\n",
      "23739     23  39952   Note_on_c       9     89     107.0\n",
      "23741     23  40312   Note_on_c       9     89      78.0\n",
      "23743     23  40336   Note_on_c       9     89     107.0\n",
      "23745     23  40800   Note_on_c       9     89      91.0\n",
      "23747     23  40828   Note_on_c       9     89     107.0\n",
      "23749     23  72960   Note_on_c       9     89      83.0\n",
      "23751     23  72980   Note_on_c       9     89     107.0\n",
      "23753     23  73336   Note_on_c       9     89      78.0\n",
      "23755     23  73360   Note_on_c       9     89     107.0\n",
      "23757     23  73824   Note_on_c       9     89      91.0\n",
      "23759     23  73848   Note_on_c       9     89     107.0,        track  time     control channel  notes  velocity\n",
      "23768     24     0   Note_on_c       9     91      77.0\n",
      "23770     24    12   Note_on_c       9     91     107.0,        track   time     control channel  notes  velocity\n",
      "23779     25      0   Note_on_c       9     93      77.0\n",
      "23781     25     20   Note_on_c       9     93     107.0\n",
      "23783     25  33020   Note_on_c       9     93      77.0\n",
      "23785     25  33036   Note_on_c       9     93     107.0,      track  time     control channel  notes  velocity\n",
      "2        2     0   Note_on_c       9     42      96.0\n",
      "3        2     0   Note_on_c       9     36      84.0\n",
      "4        2    29   Note_on_c       9     36       0.0\n",
      "5        2    29   Note_on_c       9     42       0.0\n",
      "6        2   236   Note_on_c       9     38      61.0\n",
      "..     ...   ...         ...     ...    ...       ...\n",
      "163      2  7436   Note_on_c       9     41      83.0\n",
      "164      2  7469   Note_on_c       9     42       0.0\n",
      "165      2  7469   Note_on_c       9     41       0.0\n",
      "166      2  7556   Note_on_c       9     38      43.0\n",
      "167      2  7589   Note_on_c       9     38       0.0\n",
      "\n",
      "[166 rows x 6 columns],      track  time     control channel  notes  velocity\n",
      "2        2     0   Note_on_c       9     42      96.0\n",
      "3        2     0   Note_on_c       9     36      84.0\n",
      "4        2    29   Note_on_c       9     36       0.0\n",
      "5        2    29   Note_on_c       9     42       0.0\n",
      "6        2   236   Note_on_c       9     38      61.0\n",
      "..     ...   ...         ...     ...    ...       ...\n",
      "163      2  7436   Note_on_c       9     41      83.0\n",
      "164      2  7469   Note_on_c       9     42       0.0\n",
      "165      2  7469   Note_on_c       9     41       0.0\n",
      "166      2  7556   Note_on_c       9     38      43.0\n",
      "167      2  7589   Note_on_c       9     38       0.0\n",
      "\n",
      "[166 rows x 6 columns],      track  time     control channel  notes  velocity\n",
      "2        2     0   Note_on_c       9     36      84.0\n",
      "3        2     0   Note_on_c       9     51      96.0\n",
      "4        2    29   Note_on_c       9     36       0.0\n",
      "5        2    29   Note_on_c       9     51       0.0\n",
      "6        2   476   Note_on_c       9     39      96.0\n",
      "..     ...   ...         ...     ...    ...       ...\n",
      "153      2  7229   Note_on_c       9     39       0.0\n",
      "154      2  7316   Note_on_c       9     82      53.0\n",
      "155      2  7349   Note_on_c       9     82       0.0\n",
      "156      2  7556   Note_on_c       9     39      53.0\n",
      "157      2  7589   Note_on_c       9     39       0.0\n",
      "\n",
      "[156 rows x 6 columns],      track  time     control channel  notes  velocity\n",
      "2        2     0   Note_on_c       9     41      86.0\n",
      "3        2     0   Note_on_c       9     36      84.0\n",
      "4        2     0   Note_on_c       9     51      96.0\n",
      "5        2    29   Note_on_c       9     51       0.0\n",
      "6        2    29   Note_on_c       9     41       0.0\n",
      "..     ...   ...         ...     ...    ...       ...\n",
      "185      2  7436   Note_on_c       9     53      71.0\n",
      "186      2  7469   Note_on_c       9     36       0.0\n",
      "187      2  7469   Note_on_c       9     53       0.0\n",
      "188      2  7556   Note_on_c       9     53      53.0\n",
      "189      2  7589   Note_on_c       9     53       0.0\n",
      "\n",
      "[188 rows x 6 columns]]\n",
      "{35: 0, 36: 1, 37: 2, 38: 3, 39: 4, 41: 5, 42: 6, 43: 7, 44: 8, 45: 9, 48: 10, 51: 11, 53: 12, 59: 13, 60: 14, 61: 15, 63: 16, 68: 17, 76: 18, 80: 19, 81: 20, 82: 21, 87: 22, 88: 23, 89: 24, 91: 25, 93: 26}\n",
      "{0: 35, 1: 36, 2: 37, 3: 38, 4: 39, 5: 41, 6: 42, 7: 43, 8: 44, 9: 45, 10: 48, 11: 51, 12: 53, 13: 59, 14: 60, 15: 61, 16: 63, 17: 68, 18: 76, 19: 80, 20: 81, 21: 82, 22: 87, 23: 88, 24: 89, 25: 91, 26: 93}\n"
     ]
    }
   ],
   "source": [
    "h = {}\n",
    "h_inv = {}\n",
    "unique_notes = set()\n",
    "\n",
    "maxTime = -1    # for zero padding later\n",
    "\n",
    "normalizingFactorFound = False\n",
    "for d in drumTracks_df:\n",
    "    d[\"notes\"] = d[\"notes\"].transform(lambda x : int(x))\n",
    "    unique_notes = unique_notes.union(set(d[\"notes\"]))\n",
    "    normTime = d.iloc[0][\"time\"]\n",
    "    d[\"time\"] = d[\"time\"].transform(lambda x : x - normTime)\n",
    "\n",
    "    for idx, row in d.iterrows():\n",
    "        if (row[\"time\"] > maxTime):\n",
    "            maxTime = row[\"time\"]\n",
    "\n",
    "print(drumTracks_df)\n",
    "notes = list(unique_notes)\n",
    "notes.sort()\n",
    "\n",
    "for idx in range(0, len(notes)):\n",
    "    h[notes[idx]] = idx\n",
    "    h_inv[idx] = notes[idx]        # make sure they are integers and not strings\n",
    "\n",
    "print(h)\n",
    "print(h_inv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate drum tracks into bars every 2222.222 ms is a bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors from drum track dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7590, 14)\n",
      "(7590, 14)\n"
     ]
    }
   ],
   "source": [
    "if (PROCESSING_AND_DATA_LOADING_ON):\n",
    "    S = []  # S will be a list of tuples\n",
    "            # each tuple contains two input signals over time\n",
    "\n",
    "    for df in drumTracks_df:\n",
    "        u_train, y_train = D(df, h, maxTime)\n",
    "        S.append((u_train, y_train))\n",
    "\n",
    "    u_ex, y_ex = S[0]\n",
    "    print(jax.tree_map(lambda x: x.shape, u_ex))\n",
    "    print(jax.tree_map(lambda x: x.shape, y_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save vectors so we do not have to rerun it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pynative.com/python-write-list-to-file/\n",
    "# write list to binary file\n",
    "def write_list(a_list):\n",
    "    # store list in binary file so 'wb' mode\n",
    "    with open('listfile', 'wb') as fp:\n",
    "        pickle.dump(a_list, fp)\n",
    "        print('Done writing list into a binary file')\n",
    "\n",
    "# Read list to memory\n",
    "def read_list():\n",
    "    # for reading also binary mode is important\n",
    "    with open('listfile', 'rb') as fp:\n",
    "        n_list = pickle.load(fp)\n",
    "        return n_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing list into a binary file\n"
     ]
    }
   ],
   "source": [
    "if (PROCESSING_AND_DATA_LOADING_ON):\n",
    "    write_list(S)\n",
    "else:\n",
    "    S = read_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RNN (with no LSTM units) is a neural network with recurrent connections (dynamical system)\n",
    "$$\n",
    "\\begin{array}{l l}\n",
    "          \\mathbf{x}(n+1) = \\sigma(W \\mathbf{x}(n) + W^{in}\\mathbf{u}(n+1) + \\mathbf{b}) \\\\\n",
    "          \\mathbf{y}(n) = f(W^{out} \\mathbf{x}(n)),\n",
    "\\end{array}\n",
    "$$\n",
    "Describes how the network activation state is updated and how output signal is generated. \n",
    "\n",
    "Input vector $\\mathbf{u}(n) \\in [0,1]^K$\n",
    "\n",
    "Activation/state vector $\\mathbf{x}(n) \\in \\mathbb{R}^L$\n",
    "\n",
    "Output vector $\\mathbf{y}(n) \\in \\mathbb{R}^K$\n",
    "\n",
    "Bias vector $\\mathbf{b} \\in \\mathbb{R}^L$\n",
    "\n",
    "$W^{in} \\in \\mathbb{R}^{L \\times K}, W \\in \\mathbb{R}^{L \\times L}, W^{out} \\in \\mathbb{R}^{K \\times L}$ are weight matrices charecterizing the connections between neurons in the layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "At time $n = 0$ the recurrent network state $\\mathbf{x}(0)$ is often set to the zero vector $\\mathbf{x}(0) = \\mathbf{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight_matrix(in_dim, out_dim, key, scale=1e-2):\n",
    "    w = jax.random.normal(key, (out_dim, in_dim))\n",
    "    return scale*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(dim, key, scale=1e-2):\n",
    "    b = jax.random.normal(key, (dim, ))\n",
    "    return scale*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state, params = (W^{in}, W, W^{out}, b)\n",
    "# sizes = (input dim, state dim, output dim.)\n",
    "def init_network(sizes, key):\n",
    "    keys = jax.random.split(key, len(sizes))\n",
    "    \n",
    "    Win = init_weight_matrix(sizes[0], sizes[1], keys[0])\n",
    "    W = init_weight_matrix(sizes[1], sizes[1], keys[1])\n",
    "    Wout = init_weight_matrix(sizes[1], sizes[2], keys[3])\n",
    "    b = init_bias(sizes[1], keys[2])\n",
    "\n",
    "    return (Win, W, Wout, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((100, 1), (100, 100), (1, 100), (100,))\n"
     ]
    }
   ],
   "source": [
    "#K = len(S[0][0][0]) # K := input and output vector dim\n",
    "K = 1\n",
    "L = 100 # Reservoir or State Vector dim\n",
    "sizes = [K, L, K]\n",
    "params = init_network(sizes, key)\n",
    "print(jax.tree_map(lambda x: x.shape, params)) # printing shape of network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_og is initially the zero vector\n",
    "def forward_bp(params, u, x_og=np.zeros((L, ))):\n",
    "    \"\"\" Loop over the time steps of the input sequence\n",
    "    u[n] := [u_0, ..., u_{n_max}] where u_i \\in [0, 1]^K or (K, )\n",
    "    x_og: \\in R^L or (L, )\n",
    "    \"\"\"\n",
    "    Win, W, Wout, b = params\n",
    "    x = x_og.copy()\n",
    "\n",
    "    def apply_fun_scan(params, x, ut):\n",
    "        \"\"\" Perform single step update of the network.\n",
    "        x:  (L, )\n",
    "        un: (K, )\n",
    "        \"\"\"\n",
    "        Win, W, Wout, b = params\n",
    "        x = np.tanh(\n",
    "            np.dot(Win, ut) + np.dot(W, x) + b\n",
    "        )\n",
    "        y = jax.nn.sigmoid(np.dot(Wout, x))\n",
    "        return x, y     # this returns nan at some point according to nan debugger\n",
    "\n",
    "    f = functools.partial(apply_fun_scan, params)\n",
    "    _, Y = jax.lax.scan(f, x, u)\n",
    "    return Y\n",
    "\n",
    "batch_forward_bp = jax.vmap(forward_bp, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "Logistic regression is used for the case where you do not model loudness. Because there it is a categorical task (to hit or not to hit). But if you do model loudness you use the procedure linear regression. Meaning using the loss functions that are mentioned in the RNN section of the reader like MSE or quadratic loss.\n",
    "\n",
    "Time series prediction task $S = (\\mathbf{u}^{(i)}(n), \\mathbf{y}^{(i)}(n))_{i=1, ..., N;n=1, ..., n_i}$ where $\\mathbf{y}^{i}(n) = \\mathbf{u}^{(i)}(n+1)$\n",
    "For now: quadratic loss which is used in stationary tasks\n",
    "$$\n",
    "    L(\\hat{\\mathbf{Y}}_{i, \\theta}^{\\text{train}}, \\mathbf{Y}_i^{\\text{train}}) = \\parallel \\hat{\\mathbf{Y}}_{i, \\theta}^{\\text{train}} - \\mathbf{Y}_i^{\\text{train}} \\parallel^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization\n",
    "$$\n",
    "\\text{reg}(\\theta) = \\sum_{w \\in \\theta} w^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# could be made nicer\n",
    "def getParameterVector(params):\n",
    "    theta = []\n",
    "    for w in params:\n",
    "        for e in w:\n",
    "            if (e.size > 1):\n",
    "                for i in e:\n",
    "                    theta.append(i)\n",
    "            else:\n",
    "                theta.append(e)\n",
    "    return np.array(theta)\n",
    "\n",
    "def reg(params):\n",
    "    theta = getParameterVector(params)\n",
    "    return np.sum(np.square(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{R}^{\\text{emp}}(\\theta) = \\frac{1}{N} \\sum^{N}_{i=1} L(\\hat{\\mathbf{Y}}_{i, \\theta}^{\\text{train}}, \\mathbf{Y}_i^{\\text{train}}) + r^2 \\; \\text{reg}(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, u, y_true, alpha):\n",
    "    y_hat = batch_forward_bp(params, u)\n",
    "    return np.square(np.linalg.norm(np.subtract(y_hat, y_true))) + (alpha*alpha)*reg(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\theta^{(n+1)} = \\theta^{(n)} - \\mu \\nabla \\mathcal{R}^{\\text{emp}}(\\theta^{(n)}),\n",
    "$$\n",
    "\n",
    "$$\n",
    "   \\nabla \\mathcal{R}^{\\text{emp}}(\\theta^{(n)}) = \n",
    "\\bigg(\\frac{\\partial  R^{emp}}{\\partial  w_1}(\\theta^{(n)}), ...,\\frac{\\partial  R^{emp}}{\\partial w_D}(\\theta^{(n)}) \\bigg)',\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error detected: for reasonably sized data sets after the second epoch\n",
    "the parameter vector theta = {W_in, W, W_out, b} contains nan values\n",
    "(why ?????)\n",
    "presumably: gradient is nan or is it????\n",
    "(why gradient nan -> ?????????)\n",
    "\"\"\"\n",
    "@jax.jit\n",
    "def update(params, u, y_true, alpha, step_size=1e-2):\n",
    "\n",
    "    grads = jax.grad(loss)(params, u, y_true, alpha)\n",
    "    \"\"\"\n",
    "    print(len(grads))\n",
    "    print(grads[0].shape)\n",
    "    print(grads[1].shape)\n",
    "    print(grads[2].shape)\n",
    "    print(grads[3].shape)\n",
    "    print(len(params))\n",
    "    print(params[0].shape)\n",
    "    print(params[1].shape)\n",
    "    print(params[2].shape)\n",
    "    print(params[3].shape)\n",
    "    \"\"\"\n",
    "    return [\n",
    "        (w - step_size * dw)\n",
    "        for w, dw in zip(params, grads)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanCheck(X):\n",
    "    print(np.isnan(np.sum(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\mathcal{A}(S) = \\theta_{\\text{opt}} = \\underset{\\theta \\in \\Theta}{\\text{argmin}} \\; \\underbrace{\\frac{1}{N} \\sum^N_{i=1} L(\\hat{\\mathbf{Y}}_{\\theta}^{\\text{train}}, \\mathbf{Y}^{\\text{train}})}_{\\mathcal{R}^{\\text{emp}}(\\theta)},\n",
    "$$\n",
    "$$\n",
    "    \\theta^{(n+1)} = \\theta^{(n)} - \\mu \\nabla \\mathcal{R}^{\\text{emp}}(\\theta^{(n)}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7)\n",
      "(1, 7)\n",
      "(1, 7)\n",
      "(1, 7)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scan carry output and input must have identical types, got\nDIFFERENT ShapedArray(float32[100,100]) vs. ShapedArray(float32[100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\networks\\RNNtest.ipynb Cell 41'\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=89'>90</a>\u001b[0m     \u001b[39mprint\u001b[39m(u_val\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=90'>91</a>\u001b[0m     \u001b[39mprint\u001b[39m(y_val\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=91'>92</a>\u001b[0m     params \u001b[39m=\u001b[39m train(params, u_train, y_train, u_val, y_val, r)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=92'>93</a>\u001b[0m     validation_risk\u001b[39m.\u001b[39mappend(loss(params, u_val, y_val, r))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=93'>94</a>\u001b[0m validation_risk_r\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39marray(validation_risk)))\n",
      "\u001b[1;32mc:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\networks\\RNNtest.ipynb Cell 41'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, u_train, y_train, u_test, y_test, alpha, n_epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=29'>30</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=31'>32</a>\u001b[0m     params \u001b[39m=\u001b[39m update(params, u_train, y_train, alpha)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=32'>33</a>\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(loss(params, u_train, y_train, alpha))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000039?line=33'>34</a>\u001b[0m     test_loss\u001b[39m.\u001b[39mappend(loss(params, u_test, y_test, alpha))\n",
      "    \u001b[1;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\networks\\RNNtest.ipynb Cell 37'\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(params, u, y_true, alpha, step_size)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=7'>8</a>\u001b[0m \u001b[39m@jax\u001b[39m\u001b[39m.\u001b[39mjit\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(params, u, y_true, alpha, step_size\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=10'>11</a>\u001b[0m     grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mgrad(loss)(params, u, y_true, alpha)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=11'>12</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=12'>13</a>\u001b[0m \u001b[39m    print(len(grads))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=13'>14</a>\u001b[0m \u001b[39m    print(grads[0].shape)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=21'>22</a>\u001b[0m \u001b[39m    print(params[3].shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=22'>23</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=24'>25</a>\u001b[0m         (w \u001b[39m-\u001b[39m step_size \u001b[39m*\u001b[39m dw)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=25'>26</a>\u001b[0m         \u001b[39mfor\u001b[39;00m w, dw \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params, grads)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000035?line=26'>27</a>\u001b[0m     ]\n",
      "    \u001b[1;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\networks\\RNNtest.ipynb Cell 35'\u001b[0m in \u001b[0;36mloss\u001b[1;34m(params, u, y_true, alpha)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000033?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(params, u, y_true, alpha):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000033?line=1'>2</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m batch_forward_bp(params, u)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000033?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msquare(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(np\u001b[39m.\u001b[39msubtract(y_hat, y_true))) \u001b[39m+\u001b[39m (alpha\u001b[39m*\u001b[39malpha)\u001b[39m*\u001b[39mreg(params)\n",
      "    \u001b[1;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\networks\\RNNtest.ipynb Cell 30'\u001b[0m in \u001b[0;36mforward_bp\u001b[1;34m(params, u, x_og)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000028?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x, y     \u001b[39m# this returns nan at some point according to nan debugger\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000028?line=21'>22</a>\u001b[0m f \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(apply_fun_scan, params)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000028?line=22'>23</a>\u001b[0m _, Y \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mlax\u001b[39m.\u001b[39;49mscan(f, x, u)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000028?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Y\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\lax\\control_flow.py:2243\u001b[0m, in \u001b[0;36m_check_tree_and_avals\u001b[1;34m(what, tree1, avals1, tree2, avals2)\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(_map(core\u001b[39m.\u001b[39mtypematch, avals1, avals2)):\n\u001b[0;32m   2241\u001b[0m   diff \u001b[39m=\u001b[39m tree_map(_show_diff, tree_unflatten(tree1, avals1),\n\u001b[0;32m   2242\u001b[0m                   tree_unflatten(tree2, avals2))\n\u001b[1;32m-> 2243\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mwhat\u001b[39m}\u001b[39;00m\u001b[39m must have identical types, got\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiff\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: scan carry output and input must have identical types, got\nDIFFERENT ShapedArray(float32[100,100]) vs. ShapedArray(float32[100])."
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "s is a list of tuples \n",
    "[(u1, y1), (u2, y2), ...] -> ((u_1, u_2, ...), (y_1, y_2, ...))\n",
    "a signal u_i or y_i is (K, n_i) where n_i is the length of the song which can differ\n",
    "and K is the number of modeled drum parts\n",
    "\"\"\"\n",
    "def unpack(s):\n",
    "    f1 = map(lambda x: x[0], s)\n",
    "    f2 = map(lambda x: x[1], s)\n",
    "\n",
    "    u_batch = np.array(list(f1))\n",
    "    y_batch = np.array(list(f2))\n",
    "    #nanCheck(u_batch)\n",
    "    #nanCheck(y_batch)\n",
    "    # try and remove nan values here?\n",
    "    #u_batch = u_batch[np.logical_not(np.isnan(u_batch))]\n",
    "    #y_batch = y_batch[np.logical_not(np.isnan(y_batch))]\n",
    "    return (u_batch, y_batch)\n",
    "\n",
    "\"\"\"\n",
    "trains the network on the training data for n epochs\n",
    "in the cross validations setup the testing data is\n",
    "the validation set and is simply used to measure the\n",
    "testing loss next to the training loss\n",
    "\"\"\"\n",
    "def train(params, u_train, y_train, u_test, y_test, alpha, n_epochs=10):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        params = update(params, u_train, y_train, alpha)\n",
    "        train_loss.append(loss(params, u_train, y_train, alpha))\n",
    "        test_loss.append(loss(params, u_test, y_test, alpha))\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f'Epoch {epoch+1:>2} ({epoch_time:<.2f}s): ', end='')\n",
    "        print(f'train loss {train_loss[-1]:<5.2f} test loss {test_loss[-1]:<5.2f}', end='| ')\n",
    "    \n",
    "    return params\n",
    "\n",
    "\"\"\"\n",
    "same as train but without testing set to measure testing loss\n",
    "\"\"\"\n",
    "def train2(params, u_train, y_train, r, n_epochs=2):\n",
    "    train_loss = []\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        params = update(params, u_train, y_train, r)\n",
    "        train_loss.append(loss(params, u_train, y_train, r))\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f'Epoch {epoch+1:>2} ({epoch_time:<.2f}s): ', end='')\n",
    "        print(f'train loss {train_loss[-1]:<5.2f} |')\n",
    "    return params\n",
    "\n",
    "if (TRAINING_ON and not RC_ON):\n",
    "    # given S, params, loss/emprical risk, r (regularization)\n",
    "    # Hyperparameters\n",
    "    step_size=1e-2\n",
    "    k = 2   # k fold cross validation\n",
    "    # r is the hyperparameter (here r = alpha for the regularization)\n",
    "    validation_risk_r = []\n",
    "\n",
    "    # split S into k disjoint subsets\n",
    "\n",
    "    \"\"\"\n",
    "    Edge case: if k > amount of tuples (u_train, y_train) in S then n = 0\n",
    "    which will result in a valueError when constructing S_k.\n",
    "    Furthermore: the procedure will break down for single (u_train, y_train)\n",
    "    because then the reduced training set will be the empty set\n",
    "    \"\"\"\n",
    "    n = (int) (len(S)/k)\n",
    "\n",
    "    S_k = [S[i : i + n] for i in range(0, len(S), n)]\n",
    "\n",
    "    for r in range(0, 2):\n",
    "        validation_risk = []\n",
    "        for j in range(0, k):\n",
    "            V = S_k.pop(j)                          # validation set\n",
    "            T = [x for l in S_k for x in l]         # reduced training set\n",
    "            S_k.insert(j, V)\n",
    "            u_train, y_train = unpack(T)\n",
    "            print(u_train.shape)\n",
    "            print(y_train.shape)\n",
    "            u_val, y_val = unpack(V)\n",
    "            print(u_val.shape)\n",
    "            print(y_val.shape)\n",
    "            params = train(params, u_train, y_train, u_val, y_val, r)\n",
    "            validation_risk.append(loss(params, u_val, y_val, r))\n",
    "        validation_risk_r.append(np.mean(np.array(validation_risk)))\n",
    "\n",
    "    r_opt = np.argmin(np.array(validation_risk_r))\n",
    "    u_train, y_train = unpack(V)\n",
    "    params = train2(params, u_train, y_train, r_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing list into a binary file\n"
     ]
    }
   ],
   "source": [
    "# https://pynative.com/python-write-list-to-file/\n",
    "# write list to binary file\n",
    "def write_list2(a_list):\n",
    "    # store list in binary file so 'wb' mode\n",
    "    with open('params', 'wb') as fp:\n",
    "        pickle.dump(a_list, fp)\n",
    "        print('Done writing list into a binary file')\n",
    "\n",
    "# Read list to memory\n",
    "def read_list2():\n",
    "    # for reading also binary mode is important\n",
    "    with open('params', 'rb') as fp:\n",
    "        n_list = pickle.load(fp)\n",
    "        return n_list\n",
    "\n",
    "\n",
    "if (READ_PARAMETERS):\n",
    "    params = tuple(read_list2())\n",
    "elif (SAVE_PARAMETERS):\n",
    "    write_list2(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Generation\n",
    "Get the file to prime the network with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n",
      "Invalid value encountered in the output of a jit-decorated function. Calling the de-optimized version.\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in dot_general",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\api.py:143\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[1;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m   dispatch\u001b[39m.\u001b[39;49mcheck_special(xla\u001b[39m.\u001b[39;49mxla_call_p, buffers)\n\u001b[0;32m    144\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m   \u001b[39m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\dispatch.py:539\u001b[0m, in \u001b[0;36mcheck_special\u001b[1;34m(name, bufs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[39mfor\u001b[39;00m buf \u001b[39min\u001b[39;00m bufs:\n\u001b[1;32m--> 539\u001b[0m   _check_special(name, buf\u001b[39m.\u001b[39;49mxla_shape(), buf)\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\dispatch.py:545\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, xla_shape, buf)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(buf\u001b[39m.\u001b[39mto_py())):\n\u001b[1;32m--> 545\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    546\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(buf\u001b[39m.\u001b[39mto_py())):\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in xla_call",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\dispatch.py:559\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[1;34m(name, compiled, input_handler, output_buffer_counts, result_handlers, kept_var_idx, *args)\u001b[0m\n\u001b[0;32m    558\u001b[0m out_bufs_flat \u001b[39m=\u001b[39m compiled\u001b[39m.\u001b[39mexecute(input_bufs_flat)\n\u001b[1;32m--> 559\u001b[0m check_special(name, out_bufs_flat)\n\u001b[0;32m    560\u001b[0m \u001b[39mif\u001b[39;00m output_buffer_counts \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\dispatch.py:539\u001b[0m, in \u001b[0;36mcheck_special\u001b[1;34m(name, bufs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[39mfor\u001b[39;00m buf \u001b[39min\u001b[39;00m bufs:\n\u001b[1;32m--> 539\u001b[0m   _check_special(name, buf\u001b[39m.\u001b[39;49mxla_shape(), buf)\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\dispatch.py:545\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, xla_shape, buf)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(buf\u001b[39m.\u001b[39mto_py())):\n\u001b[1;32m--> 545\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    546\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(buf\u001b[39m.\u001b[39mto_py())):\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in dot",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\networks\\RNNtest.ipynb Cell 44'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((L,))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_stop):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=24'>25</a>\u001b[0m     x, y \u001b[39m=\u001b[39m apply_fun_scan(params, x, u_prime[n])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=25'>26</a>\u001b[0m     y_signal\u001b[39m.\u001b[39mappend(y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_output):\n",
      "\u001b[1;32mc:\\Users\\Matth\\OneDrive\\Documenten\\NN\\semester-project\\networks\\RNNtest.ipynb Cell 44'\u001b[0m in \u001b[0;36mapply_fun_scan\u001b[1;34m(params, x, un)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=1'>2</a>\u001b[0m \u001b[39m\"\"\" Perform single step update of the network.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=2'>3</a>\u001b[0m \u001b[39mx:  (L, ) at time step n -> x: (L, ) at time step n+1\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=3'>4</a>\u001b[0m \u001b[39mun: (K, )\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=5'>6</a>\u001b[0m Win, W, Wout, b \u001b[39m=\u001b[39m params\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=7'>8</a>\u001b[0m     np\u001b[39m.\u001b[39mdot(Win, un) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49mdot(W, x) \u001b[39m+\u001b[39m b\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=8'>9</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=9'>10</a>\u001b[0m y \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msigmoid(np\u001b[39m.\u001b[39mdot(Wout, x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Matth/OneDrive/Documenten/NN/semester-project/networks/RNNtest.ipynb#ch0000043?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x, y\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\api.py:149\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[1;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39massert\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mor\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs\n\u001b[0;32m    147\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInvalid nan value encountered in the output of a C++-jit/pmap \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfunction. Calling the de-optimized version.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 149\u001b[0m fun\u001b[39m.\u001b[39m_cache_miss(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)[\u001b[39m0\u001b[39m]\n",
      "    \u001b[1;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:2692\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(a, b, precision)\u001b[0m\n\u001b[0;32m   2690\u001b[0m   \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mmul(a, b)\n\u001b[0;32m   2691\u001b[0m \u001b[39mif\u001b[39;00m _max(a_ndim, b_ndim) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 2692\u001b[0m   \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39;49mdot(a, b, precision\u001b[39m=\u001b[39;49mprecision)\n\u001b[0;32m   2694\u001b[0m \u001b[39mif\u001b[39;00m b_ndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2695\u001b[0m   contract_dims \u001b[39m=\u001b[39m ((a_ndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,), (\u001b[39m0\u001b[39m,))\n",
      "    \u001b[1;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Matth\\anaconda3\\envs\\tf\\lib\\site-packages\\jax\\_src\\dispatch.py:545\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, xla_shape, buf)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39mif\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(xla_shape\u001b[39m.\u001b[39melement_type(), np\u001b[39m.\u001b[39minexact):\n\u001b[0;32m    544\u001b[0m   \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(buf\u001b[39m.\u001b[39mto_py())):\n\u001b[1;32m--> 545\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    546\u001b[0m   \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(buf\u001b[39m.\u001b[39mto_py())):\n\u001b[0;32m    547\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (inf) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in dot_general"
     ]
    }
   ],
   "source": [
    "def apply_fun_scan(params, x, un):\n",
    "    \"\"\" Perform single step update of the network.\n",
    "    x:  (L, ) at time step n -> x: (L, ) at time step n+1\n",
    "    un: (K, )\n",
    "    \"\"\"\n",
    "    Win, W, Wout, b = params\n",
    "    x = jax.nn.relu(\n",
    "        np.dot(Win, un) + np.dot(W, x) + b\n",
    "    )\n",
    "    y = jax.nn.sigmoid(np.dot(Wout, x))\n",
    "    return x, y\n",
    "\n",
    "columnNames = [\"track\", \"time\", \"control\"\n",
    "                                , \"channel\", \"notes\", \"velocity\"]\n",
    "\n",
    "df1 = pd.read_csv('drumDemo.csv', skipfooter=2, skiprows=8, engine='python', names= columnNames)\n",
    "\n",
    "u_prime = D(df1, h, maxTime)[0]\n",
    "n_stop = 1000\n",
    "n_output = 8000\n",
    "\n",
    "y_signal = []\n",
    "x = np.zeros((L,))\n",
    "for n in range(n_stop):\n",
    "    x, y = apply_fun_scan(params, x, u_prime[n])\n",
    "    y_signal.append(y)\n",
    "\n",
    "for n in range(n_output):\n",
    "    x, y = apply_fun_scan(params, x, y)\n",
    "    y_signal.append(y)\n",
    "\n",
    "print(y_signal)\n",
    "dfo = D_inv(np.array(y_signal), h_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{M}^{-1} : \\text{CSV} \\rightarrow \\text{MIDI}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Puts generated CSV file in correct folder\n",
    "and generates the MIDI file and puts that in the correct\n",
    "folder as well.\n",
    "\"\"\"\n",
    "# for debugging: checking highest amplitude in output signal\n",
    "\"\"\"\n",
    "v = -99999999999999\n",
    "for e in y_signal:\n",
    "    if e.max() >= v:\n",
    "        v = e.max()\n",
    "print(v)\n",
    "\"\"\"\n",
    "\n",
    "os.chdir('../midi/NetworkOutputCSV')\n",
    "name = \"rnn.csv\"\n",
    "dfo.to_csv(name, index = False, header = False)\n",
    "copy(name, '../midicsv-1.1')\n",
    "os.chdir('../midicsv-1.1')\n",
    "\n",
    "command = \"csvmidi\" + \" \" + name + \" \" + name[:-4] + \".mid\"\n",
    "res = os.system(command)\n",
    "print(res)\n",
    "os.remove(name)\n",
    "try:\n",
    "    move(name[:-4] + \".mid\", '../NetworkOutputMIDI')\n",
    "except:\n",
    "    print(\"midi file already here\")\n",
    "    os.remove(name[:-4] + \".mid\")\n",
    "\n",
    "os.chdir(cwd)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental: reservoir computing\n",
    "dimensionality $K, L, K$ same: using same rnn.\n",
    "First: scaling with spectral radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (RC_ON):\n",
    "    W, Win, Wout, b = params\n",
    "    rhoW = np.max(np.absolute(np.linalg.eig(W)[0]))\n",
    "    scale = 1.25\n",
    "    W = (scale/rhoW)*W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: state harvesting: record activation for each of the $L$ reservoir neurons\n",
    "when driven by teacher input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(u, Win, W, b, Wout=None, x_init=np.zeros((L, ))):\n",
    "    # u: (n_max, K)\n",
    "    n_max = u.shape[0]\n",
    "    K = u.shape[1]\n",
    "    X, Y = [], []\n",
    "    # X: (1+K+L, n_max)\n",
    "    # Y: (K, n_max) double chheck later\n",
    "    x = x_init.copy()\n",
    "    for t in range(u.shape[0]):\n",
    "        x = np.tanh(\n",
    "            np.dot(Win, u[t]) + np.dot(W, x) + b\n",
    "        )\n",
    "        full_state = np.concatenate(u[t], x, b)\n",
    "        X.append(full_state)\n",
    "        if Wout is not None:\n",
    "            y = np.dot(Wout, full_state)\n",
    "            Y.append(y)\n",
    "        # when returning: need to transpose data arrays, such that dim: (n_max, x)\n",
    "    if Wout is None:\n",
    "        return x, np.array(X).T\n",
    "    else:\n",
    "        return x, np.array(X).T, np.array(Y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (RC_ON):\n",
    "    x, X = forward(u_train[0], Win, W)\n",
    "    print(f'u: {u_train[0].shape}, x: {x.shape}, X: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2: compute readouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (RC_ON):\n",
    "    reg = 1e-8\n",
    "\n",
    "    Wout_rc_ = np.dot(\n",
    "        np.dot(y_train[0].T, X.T),\n",
    "        np.linalg.inv(\n",
    "            np.dot(X, X.T) + reg*np.eye(1+K+L)\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e375b77a672b76be28c1e80386a6d4db61c866c142c6acff7bc94a65b4573147"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
