{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Simple) RNN in Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import math\n",
    "import numpy as onp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import grad, vmap, jit\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre - and Postprocessing\n",
    "$$\n",
    "  \\mathcal{D} : \\text{CSV} \\rightarrow [0,1]^{K \\times n_{\\max}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D(df):\n",
    "    time = df[\"time\"].values\n",
    "    notes = df[\"notes\"].values\n",
    "    velocity = df[\"velocity\"].values\n",
    "    h = {}\n",
    "    h[36] = 0\n",
    "    h[38] = 1\n",
    "    h[41] = 2\n",
    "    h[42] = 3\n",
    "    h[43] = 4\n",
    "    h[45] = 5\n",
    "    h[82] = 6\n",
    "\n",
    "    u = list(itertools.repeat(np.zeros(7), max(time)+1))\n",
    "\n",
    "    for i in range(len(notes)):\n",
    "        v = [0]*7\n",
    "        v[h[notes[i]]] = velocity[i] / 127\n",
    "        if (np.any(u[time[i]])):        #If the current vector is not the zero vector\n",
    "            u[time[i]] = u[time[i]] + np.array(v)\n",
    "        else:\n",
    "            u[time[i]] = np.array(v)\n",
    "    \n",
    "    y_train = u[1:]\n",
    "    y_train.append(np.zeros(7))\n",
    "    return np.array(u), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{D}^{-1} : [0,1]^{K \\times n_{max}} \\rightarrow \\text{CSV}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_inv(y):\n",
    "    h_inv = {}\n",
    "    h_inv[0] = 36\n",
    "    h_inv[1] = 38\n",
    "    h_inv[2] = 41\n",
    "    h_inv[3] = 42\n",
    "    h_inv[4] = 43\n",
    "    h_inv[5] = 45\n",
    "    h_inv[6] = 82\n",
    "\n",
    "    dfo = pd.DataFrame([], columns= [\"track\", \"time\", \"note_is_played\"\n",
    "                            ,\"channel\", \"notes\", \"velocity\"])\n",
    "    time_new = []\n",
    "    notes_new = []\n",
    "    velocity_new = []\n",
    "\n",
    "    for n in range(len(y)):\n",
    "        if (np.any(y[n])):\n",
    "            yn = y[n]\n",
    "            for i in range(len(yn)):\n",
    "                v = (int)(yn[i] * 127)\n",
    "                if (v > 0):\n",
    "                    time_new.append(n)\n",
    "                    velocity_new.append(v)\n",
    "                    notes_new.append(h_inv[i])\n",
    "\n",
    "    track_new = [2]*len(time_new)       # arbitrary\n",
    "    note_is_played_new = [\"Note_on_c\"]*len(time_new)\n",
    "    channel_new = [9]*len(time_new)     # 9 for drum\n",
    "\n",
    "    dfo[\"track\"] = track_new\n",
    "    dfo[\"note_is_played\"] = note_is_played_new\n",
    "    dfo[\"channel\"] = channel_new\n",
    "    dfo[\"time\"] = time_new\n",
    "    dfo[\"velocity\"] = velocity_new\n",
    "    dfo[\"notes\"] = notes_new\n",
    "\n",
    "    latestTime = time_new[-1] + 10\n",
    "\n",
    "    pre = [[0,0, \"Header\", 1, 2, 480, ''],\n",
    "            [1, 0, \"Start_track\", '', '', '', ''],\n",
    "            [1, 0, \"Time_signature\", 4, 2, 24, 8],\n",
    "            [1, 0, \"Title_t\", \"\\\"from model\\\"\", '', '', ''],\n",
    "            [1, 0, \"End_track\", '', '', '', ''],\n",
    "            [2, 0, \"Start_track\", '', '', '', '']]\n",
    "\n",
    "    post = [[2, latestTime, \"End_track\", '', '', '', ''],\n",
    "            [0, 0, \"End_of_file\", '', '', '', '']]\n",
    "\n",
    "    dfo[\"filler\"] = ''\n",
    "    # adding pre and post\n",
    "    for i in range(len(pre)):\n",
    "        dfo.loc[i] = pre[i]\n",
    "    for j in range(len(post)):\n",
    "        dfo.loc[len(dfo)+j] = post[j]\n",
    "\n",
    "    dfo.to_csv(\"new.csv\", index = False, header = False)\n",
    "    return dfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBD: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7590, 7)\n",
      "(7590, 7)\n"
     ]
    }
   ],
   "source": [
    "columnNames = [\"track\", \"time\", \"note_is_played\"\n",
    "                            , \"channel\", \"notes\", \"velocity\"]\n",
    "\n",
    "df = pd.read_csv('drumDemo.csv', skipfooter=2, skiprows=8, engine='python', names= columnNames)\n",
    "\n",
    "u = []\n",
    "y_train = []\n",
    "\n",
    "u_i, ytrain_i = D(df)\n",
    "\n",
    "u.append(u_i)\n",
    "y_train.append(ytrain_i)\n",
    "\n",
    "print(jax.tree_map(lambda x: x.shape, u[0]))\n",
    "print(jax.tree_map(lambda x: x.shape, y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RNN (with no LSTM units) is a neural network with recurrent connections (dynamical system)\n",
    "$$\n",
    "\\begin{array}{l l}\n",
    "          \\mathbf{x}(n+1) = \\sigma(W \\mathbf{x}(n) + W^{in}\\mathbf{u}(n+1) + \\mathbf{b}) \\\\\n",
    "          \\mathbf{y}(n) = f(W^{out} \\mathbf{x}(n)),\n",
    "\\end{array}\n",
    "$$\n",
    "Describes how the network activation state is updated and how output signal is generated. \n",
    "\n",
    "Input vector $\\mathbf{u}(n) \\in [0,1]^K$\n",
    "\n",
    "Activation/state vector $\\mathbf{x}(n) \\in \\mathbb{R}^L$\n",
    "\n",
    "Output vector $\\mathbf{y}(n) \\in \\mathbb{R}^K$\n",
    "\n",
    "Bias vector $\\mathbf{b} \\in \\mathbb{R}^L$\n",
    "\n",
    "$W^{in} \\in \\mathbb{R}^{L \\times K}, W \\in \\mathbb{R}^{L \\times L}, W^{out} \\in \\mathbb{R}^{K \\times L}$ are weight matrices charecterizing the connections between neurons in the layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "At time $n = 0$ the recurrent network state $\\mathbf{x}(0)$ is often set to the zero vector $\\mathbf{x}(0) = \\mathbf{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight_matrix(in_dim, out_dim, key, scale=1e-2):\n",
    "    w = jax.random.normal(key, (out_dim, in_dim))\n",
    "    return scale*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(dim, key, scale=1e-2):\n",
    "    b = jax.random.normal(key, (dim, ))\n",
    "    return scale*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state, params = (W^{in}, W, W^{out}, b)\n",
    "# sizes = (input dim, state dim, output dim.)\n",
    "def init_network(sizes, key):\n",
    "    keys = jax.random.split(key, len(sizes))\n",
    "    params = {} # hashmap\n",
    "    # don't know if this is the best way to do it but this is to keep track of the state vector over time\n",
    "    x = []\n",
    "    x.append(np.zeros(sizes[1]))\n",
    "    # as well as output signal\n",
    "    y = []\n",
    "    \n",
    "    params[\"input matrix\"] = init_weight_matrix(sizes[0], sizes[1], keys[0])\n",
    "    params[\"state matrix\"] = init_weight_matrix(sizes[1], sizes[1], keys[1])\n",
    "    params[\"output matrix\"] = init_weight_matrix(sizes[1], sizes[2], keys[3])\n",
    "    params[\"bias vector\"] = init_bias(sizes[1], keys[2])\n",
    "\n",
    "    return x, y, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias vector': (12,), 'input matrix': (12, 7), 'output matrix': (7, 12), 'state matrix': (12, 12)}\n"
     ]
    }
   ],
   "source": [
    "K = 7 # K := input and output vector dim\n",
    "L = 12 # Reservoir or State Vector dim\n",
    "sizes = [K, L, K]\n",
    "x, y, params = init_network(sizes, key)\n",
    "print(jax.tree_map(lambda x: x.shape, params)) # printing shape of network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathbf{x}(n+1) = \\sigma(W \\mathbf{x}(n) + W^{in}\\mathbf{u}(n+1) + \\mathbf{b})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = weights and bias\n",
    "# u = input signal at time n\n",
    "# x = state vector : returns state at time n\n",
    "# b = bias vector\n",
    "# n = time\n",
    "# changed: the entire state vector and input signal is passed now\n",
    "# adds new state vector to state signal and also returns new state vector\n",
    "def nextState(params, x, u, n):\n",
    "    w_in = params[\"input matrix\"]\n",
    "    w = params[\"state matrix\"]\n",
    "    b = params[\"bias vector\"]\n",
    "    x_new = jax.nn.relu(np.dot(w, x[-1]) + np.dot(w_in, u[n]) + b)\n",
    "    x.append(x_new)\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{y}(n) = f(W^{out} \\mathbf{x}(n))$$\n",
    "$f$ is a function that ensures the readout $W^{out} \\mathbf{x}(n) \\in \\mathbb{R}^{K} \\mapsto \\mathbf{y}(n) \\in [0,1]^K$. In other words, that the output of the network has vectors whose elements are always between $0$ and $1$:\n",
    "$$\n",
    "       f(x) := \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "Both $\\sigma$ and $f$ are applied element-wise on a given vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds new output vector to output signal and also returns new output vector\n",
    "def readOut(params, x, y):\n",
    "    w_out = params[\"output matrix\"]\n",
    "    y_new = jax.nn.sigmoid(np.dot(w_out, x[-1]))\n",
    "    y.append(y_new)\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input signal\n",
    "$$\n",
    "\\mathbf{u}[n]_{n=0, ..., n_{max}} \\in [0,1]^K\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor n in range(len(u)):\\n    nextState(params, x, u, n)\\n    readOut(params, x, y)\\n'"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for n in range(len(u)):\n",
    "    nextState(params, x, u, n)\n",
    "    readOut(params, x, y)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some printing\n",
    "# note: u is a jax numpy matrix\n",
    "# x, y are lists whose elements are jax numpy arrays\n",
    "# but u[i], x[i], y[i] are all jax numpy arrays\n",
    "#print(u[20])\n",
    "#print(type(u))\n",
    "#print(type(u[2]))\n",
    "#print(x[20])\n",
    "#print(type(x))\n",
    "#print(type(x[2]))\n",
    "#print(y[20])\n",
    "#print(type(y))\n",
    "#print(type(y[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_og is initially the zero vector\n",
    "def forward_bp(params, u, x_og=np.zeros((L, ))):\n",
    "    \"\"\" Loop over the time steps of the input sequence\n",
    "    u[n] := [u_0, ..., u_{n_max}] where u_i \\in [0, 1]^K or (K, )\n",
    "    x_og: \\in R^L or (L, )\n",
    "    \"\"\"\n",
    "    Win, W, Wout, b = params.values()\n",
    "    x = x_og.copy()\n",
    "\n",
    "    def apply_fun_scan(params, x, ut):\n",
    "        \"\"\" Perform single step update of the network.\n",
    "        x:  (L, )\n",
    "        un: (K, )\n",
    "        \"\"\"\n",
    "        Win, W, Wout, b = params.values()\n",
    "        x = jax.nn.relu(\n",
    "            np.dot(Win, ut) + np.dot(W, x) + b\n",
    "        )\n",
    "        y = jax.nn.sigmoid(np.dot(Wout, x))\n",
    "        return x, y\n",
    "\n",
    "    f = functools.partial(apply_fun_scan, params)\n",
    "    _, Y = jax.lax.scan(f, x, u)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12,)]\n",
      "(7590, 7)\n",
      "(7590, 7)\n",
      "(7,)\n",
      "[0.49994802 0.49992424 0.49997348 0.4999168  0.4999715  0.49996275\n",
      " 0.5000249 ]\n",
      "[0.49994802 0.49992424 0.49997348 0.4999168  0.4999715  0.49996275\n",
      " 0.5000249 ]\n"
     ]
    }
   ],
   "source": [
    "print(jax.tree_map(lambda x: x.shape, x))\n",
    "print(jax.tree_map(lambda x: x.shape, u[0]))\n",
    "Y = forward_bp(params, u[0])\n",
    "print(jax.tree_map(lambda x: x.shape, Y))\n",
    "print(jax.tree_map(lambda x: x.shape, Y[0]))\n",
    "\n",
    "print(Y[7589])\n",
    "print(Y[7590])\n",
    "\n",
    "# u[n] (7,)\n",
    "# y[n] = u[n+1] (7,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "Logistic regression is used for the case where you do not model loudness. Because there it is a categorical task (to hit or not to hit). But if you do model loudness you use the procedure linear regression. Meaning using the loss functions that are mentioned in the RNN section of the reader like MSE or quadratic loss.\n",
    "\n",
    "Time series prediction task $S = (\\mathbf{u}^{(i)}(n), \\mathbf{y}^{(i)}(n))_{i=1, ..., N;n=1, ..., n_i}$ where $\\mathbf{y}^{i}(n) = \\mathbf{u}^{(i)}(n+1)$\n",
    "For now: quadratic loss which is used in stationary tasks\n",
    "$$\n",
    "    L(\\hat{\\mathbf{Y}}_{i, \\theta}^{\\text{train}}, \\mathbf{Y}_i^{\\text{train}}) = \\parallel \\hat{\\mathbf{Y}}_{i, \\theta}^{\\text{train}}, \\mathbf{Y}_i^{\\text{train}} \\parallel^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, u, y_true):\n",
    "    y_hat = forward_bp(params, u)\n",
    "    return np.square(np.linalg.norm(np.subtract(y_hat, y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7590, 7)\n",
      "(7590, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(13261.639, dtype=float32)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(u[0].shape)\n",
    "print(y_train[0].shape)\n",
    "loss(params, u[0], y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\mathcal{A}(S) = \\theta_{\\text{opt}} = \\underset{\\theta \\in \\Theta}{\\text{argmin}} \\; \\underbrace{\\frac{1}{N} \\sum^N_{i=1} L(\\hat{\\mathbf{Y}}_{\\theta}^{\\text{train}}, \\mathbf{Y}^{\\text{train}})}_{\\mathcal{R}^{\\text{emp}}(\\theta)},\n",
    "$$\n",
    "$$\n",
    "    \\theta^{(n+1)} = \\theta^{(n)} - \\mu \\nabla \\mathcal{R}^{\\text{emp}}(\\theta^{(n)}),\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e375b77a672b76be28c1e80386a6d4db61c866c142c6acff7bc94a65b4573147"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
